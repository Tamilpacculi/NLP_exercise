import json
import time
import pandas as pd
import numpy as np
from bs4 import BeautifulSoup
import requests
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn import metrics
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import SGDClassifier
# from sklearn.model_selection import GridSearchCV
# import matplotlib.pyplot as plt

# preparation works for train and validation data
page = 1  # set default page number
n_component = 0  # initially, the 0th component in the list
company = 'facebook'
company_name = []
date_published = []
rating_value = []
review_body = []
n_review = 2000


while len(company_name) < n_review:
    # to accumulate 500 results by change the page number
    # and only sent the request while all reviews on
    # one pages have been retrieved

    resp = requests.get(
        'https://www.trustpilot.com/review/www.'
        + company
        + '.com?page='
        + str(page), timeout=5
        )
    html_code = resp.text
    soup = BeautifulSoup(html_code,  features='lxml')
    reviews = soup.find('script', type="application/ld+json")
    # locate where the reviews are
    reviews = reviews.get_text()
    # convert from NavigatableString generated by BeautifulSoup to String
    # so that it can be converted to json and extract elements from json
    json_data = json.loads(reviews)

    while n_component < len(json_data['@graph']):
        # The while loop is to retrieve data from each page
        # the while loop is to make sure all reviews have been
        # retrieved before move on
        # and categorize the retrieved data and add them to
        # proper lists in the if loop

        if json_data['@graph'][n_component].get('@type') == 'Review':
            # in the if loop, the condition is to make sure
            # only retrieve Reviews not others

            company_name.append(json_data['@graph'][6].get('name'))
            # company name is not in reviews, so need to find in proper place
            # at "@type":"LocalBusiness" the seventh item in the list,
            # a fixed place in the list

            date_published.append(json_data['@graph']
                                  [n_component].get('datePublished'))
            # add to date
            rating_value.append(json_data['@graph']
                                [n_component].get(
                                'reviewRating').get('ratingValue'))
            # add to rating
            review_body.append(json_data['@graph']
                               [n_component].get('reviewBody'))
            # add to review text
            n_component = n_component + 1
            # print(json_data['@graph'][n_component])

        else:
            n_component = n_component + 1


    page = page + 1
    n_component = 0
    print(str(len(company_name))+'/'+str(n_review)+' reviews retrieved')
        # reset the n_components so the while loop won't run forever
        # because otherwise the n_component will never
        # less than len(json_data['@graph'])
        # and the page = page + 1 will run instead,
        # and since there is nothing
        # added to company_name list, the while len(company_name) < 500
        # will run forever

    time.sleep(5)
    # just to reduce the risk of being blacklisted by the website


# prepare the lists and convert them to dataframe before output to csv
#START_CODE
temp_list1 = list(zip(company_name, date_published))
temp_list2 = list(zip(rating_value, review_body))
df1 = pd.DataFrame(temp_list1, columns=['companyName', 'datePublished'])
df2 = pd.DataFrame(temp_list2, columns=['ratingValue',  'reviewBody'])
df_final = pd.concat([df1, df2],  axis=1)
# df_final is the final result in dataframe form
df_final.to_csv('reviews.csv', index=False)


# print total number of reviews
print('Total reviews:'
      + str(json_data['@graph'][6].get('aggregateRating').get('reviewCount')))

# preparation works for test data
page = 81
n_component = 0
company = 'facebook'
company_name = []
date_published = []
rating_value = []
review_body = []
n_review = 500


while len(company_name) < n_review:

    resp = requests.get(
        'https://www.trustpilot.com/review/www.'
        + company
        + '.com?page='
        + str(page), timeout=5
        )
    html_code = resp.text
    soup = BeautifulSoup(html_code,  features='lxml')
    reviews = soup.find('script', type="application/ld+json")
    reviews = reviews.get_text()
    json_data = json.loads(reviews)

    while n_component < len(json_data['@graph']):
        if json_data['@graph'][n_component].get('@type') == 'Review':
            company_name.append(json_data['@graph'][6].get('name'))
            date_published.append(json_data['@graph']
                                  [n_component].get('datePublished'))
            rating_value.append(json_data['@graph']
                                [n_component].get(
                                'reviewRating').get('ratingValue'))
            review_body.append(json_data['@graph']
                               [n_component].get('reviewBody'))
            n_component = n_component + 1

        else:
            n_component = n_component + 1


    page = page + 1
    n_component = 0
    print(str(len(company_name))+'/'+str(n_review)+' reviews retrieved')

    time.sleep(5)


temp_list1 = list(zip(company_name, date_published))
temp_list2 = list(zip(rating_value, review_body))
df1 = pd.DataFrame(temp_list1, columns=['companyName', 'datePublished'])
df2 = pd.DataFrame(temp_list2, columns=['ratingValue',  'reviewBody'])
df_final = pd.concat([df1, df2],  axis=1)
df_final.to_csv('test.csv', index=False)


data = pd.read_csv('reviews.csv')
data = pd.DataFrame(data)

# assign Sentiment values
data['Sentiment'] = data['ratingValue']
data.loc[data['ratingValue'] == 1, 'Sentiment'] = 0
data.loc[data['ratingValue'] == 2, 'Sentiment'] = 1
data.loc[data['ratingValue'] == 3, 'Sentiment'] = 1
data.loc[data['ratingValue'] == 4, 'Sentiment'] = 2
data.loc[data['ratingValue'] == 5, 'Sentiment'] = 2


# define a function for preprocess train, valid and test datasets
def preprocessing(n):
    negative = int(data.loc[data['Sentiment'] == 0, 'Sentiment'].count())
    neutral = int(data.loc[data['Sentiment'] == 1, 'Sentiment'].count())
    positive = int(data.loc[data['Sentiment'] == 2, 'Sentiment'].count())

    # find the median of negative, neutral and positive rating if
    # the number of three ratings are close
    if negative+neutral < positive:
        desired_amount = np.mean([negative, neutral, positive])
    elif negative+positive < neutral:
        desired_amount = np.mean([negative, neutral, positive])
    elif neutral+positive < negative:
        desired_amount = np.mean([negative, neutral, positive])
    else:
        desired_amount = np.median([negative, neutral, positive])

    data1 = data.copy()

    # complete the processed dataset for a more evenly distributed
    # negative, neutral and positive rating
    if negative > desired_amount:
        amount_drop = negative-desired_amount
        percent_amount_drop = float(amount_drop/negative)
        data_drop_n = data1.loc[data1['Sentiment'] == 0].sample(
            frac=percent_amount_drop)
        data1 = data1.drop(data_drop_n.index)
        data1 = data1.reset_index(drop=True)

    if neutral > desired_amount:
        amount_drop = neutral-desired_amount
        percent_amount_drop = float(amount_drop/neutral)
        data_drop_neu = data1.loc[data1['Sentiment'] == 1].sample(
            frac=percent_amount_drop)
        data1 = data1.drop(data_drop_neu.index)
        data1 = data1.reset_index(drop=True)

    if positive > desired_amount:
        amount_drop = positive-desired_amount
        percent_amount_drop = float(amount_drop/positive)
        data_drop_p = data1.loc[data1['Sentiment'] == 2].sample(
            frac=percent_amount_drop)
        data1 = data1.drop(data_drop_p.index)
        data1 = data1.reset_index(drop=True)

    # split the train portion as 75% of the total
    train_portion = 0.75
    train_set = data1.sample(frac=train_portion)
    val_set = data1.drop(train_set.index)
    train_set = train_set.reset_index(drop=True)
    val_set = val_set.reset_index(drop=True)

    # save as two csv
    train_set.to_csv('train.csv')
    val_set.to_csv('valid.csv')

    # drop unnecessary columns
    train = pd.read_csv('train.csv')
    train_corpus = train['reviewBody']
    train_label = train['Sentiment']
    train_set_new = pd.DataFrame(train_corpus)
    train_set_new['Sentiment'] = train_label

    val = pd.read_csv('valid.csv')
    val_corpus = val['reviewBody']
    val_label = val['Sentiment']
    val_set_new = pd.DataFrame(val_corpus)
    val_set_new['Sentiment'] = val_label

    # prepared for test dataset for grading
    global loaded
    try:
        test = pd.read_csv('test.csv')
        test['Sentiment'] = test['ratingValue']
        test.loc[test['ratingValue'] <= 2, 'Sentiment'] = 0
        test.loc[test['ratingValue'] == 3, 'Sentiment'] = 1
        test.loc[test['ratingValue'] > 3, 'Sentiment'] = 2
        test_corpus = test['reviewBody']
        test_label = test['Sentiment']
        test_set_new = pd.DataFrame(test_corpus)
        test_set_new['Sentiment'] = test_label
        test_set_new = pd.DataFrame(test_set_new)
        loaded = True
    except Exception:
        loaded = False

    if n == 'train':
        print('Before: ')
        print('negative rating: '
              + str(data.loc[data['Sentiment'] == 0, 'Sentiment'].count()))
        print('neutral rating: '
              + str(data.loc[data['Sentiment'] == 1, 'Sentiment'].count()))
        print('positive rating: '
              + str(data.loc[data['Sentiment'] == 2, 'Sentiment'].count()))
        print('total: '
              + str(data.loc[data['Sentiment'], 'Sentiment'].count()))
        print(' ')

        print('After: ')
        print('negative rating: '
              + str(data1.loc[data1['Sentiment'] == 0, 'Sentiment'].count()))
        print('neutral rating: '
              + str(data1.loc[data1['Sentiment'] == 1, 'Sentiment'].count()))
        print('positive rating: '
              + str(data1.loc[data1['Sentiment'] == 2, 'Sentiment'].count()))
        print('total: '
              + str(data1.loc[data1['Sentiment'], 'Sentiment'].count()))
        print(' ')
        print('train set shape: '
              + str(train_set_new.shape))
        print(' ')
        return train_set_new

    elif n == 'val':
        print('validation set shape: ' + str(val_set_new.shape))
        print(' ')
        return val_set_new

    elif n == 'test' and loaded is True:
        print('test set shape: ' + str(test_set_new.shape))
        print(' ')
        return test_set_new

    elif n == 'test' and loaded is False:
        print(' ')
        print('please load test.csv first')

    else:
        print("have you loaded something?\n"
              "try run preprocess('train')\n"
              "or run preprocess('val')\n"
              )


# prepare train and validation datasets
train = preprocessing('train')
val = preprocessing('val')

x_train = train['reviewBody']
y_train = train['Sentiment']
x_val = val['reviewBody']
y_val = val['Sentiment']

n = 1
clf_series = {'SVC': SVC(C=10, degree=1, kernel='linear'),
              'MLP': MLPClassifier(activation='relu', solver='adam',
                                   alpha=0.0001, learning_rate='constant'),
              'SGD': SGDClassifier(alpha=0.0001, loss='modified_huber',
                                   penalty='elasticnet'),
              'Random Forest': RandomForestClassifier(criterion='entropy',
                                                      n_estimators=500),
              'Decision Tree': DecisionTreeClassifier(criterion='entropy')
              }

accuracy = []
f1_score_avg = []
f1_scores_0 = []
f1_scores_1 = []
f1_scores_2 = []

while n < len(clf_series):
    n = 1
    for i in clf_series.items():
        # cv is used for tokenizing the reviews
        # to build a volcabulary
        # tt is used for count the occurance of volcabularies
        cv = CountVectorizer(ngram_range=(3, 5), analyzer='char')
        tt = TfidfTransformer()
        clf = i[1]

        # use train data to fit the models then transform
        x_train_count = cv.fit_transform(x_train)
        x_train_tfidf = tt.fit_transform(x_train_count)

        # when comes to valid data, only need to
        # transform valid data using trained models
        x_val_count = cv.transform(x_val)
        x_val_tfidf = tt.transform(x_val_count)

        # used neural network classification
        clf.fit(x_train_tfidf, y_train)
        y_pred = clf.predict(x_val_tfidf)

        # to tune parameters
        '''
        parameters = {
            'activation': ['tanh', 'relu'],
            'solver': ['lbfgs', 'adam'],
            'alpha': [0.0001, 0.001, 0.01, 0.1],
            'learning_rate': ['constant', 'adaptive']
        }

        optimal = GridSearchCV(clf, parameters, n_jobs=-1, cv=5)
        optimal.fit(x_train_tfidf, y_train)
        print(optimal.best_estimator_)
        '''

        # print model performances
        print('Validation: {}'.format(str(i[0])))
        print('--------------------------------------------')
        # accuracy score
        accuracy.append(metrics.accuracy_score(y_val, y_pred))

        f1_score = metrics.classification_report(
                   y_val, y_pred, output_dict=True)
        # average f1_score using macro method
        f1_score_avg.append(metrics.f1_score(y_val, y_pred, average='macro'))

        # by-class f1_score
        f1_scores_0.append(f1_score.get('0', {}).get('f1-score'))
        f1_scores_1.append(f1_score.get('1', {}).get('f1-score'))
        f1_scores_2.append(f1_score.get('2', {}).get('f1-score'))

        print('Confusion matrix of {}: '.format(i[0]))
        # confusion matrix in number format
        confusion_matrix = pd.DataFrame(
                           metrics.confusion_matrix(y_val, y_pred,
                                                    labels=clf.classes_))
        confusion_matrix.columns = ['Negative', 'Neutral', 'Positive']
        confusion_matrix.insert(0, ' ', ['Negative', 'Neutral', 'Positive'],
                                allow_duplicates=True)
        print(confusion_matrix)
        print(' ')


        # confusion matrix in graph format
        # confu_matrix = metrics.confusion_matrix(y_val, y_pred,
        #                                        labels=clf.classes_)
        # matrix = metrics.ConfusionMatrixDisplay(
        #          confusion_matrix=confu_matrix,
        #          display_labels=['negative', 'neutral', 'positive'])
        # matrix.plot()
        # plt.show()


        n = n + 1

# model selction
accuracy = pd.DataFrame(accuracy)
f1_score_avg = pd.DataFrame(f1_score_avg)
f1_scores_0 = pd.DataFrame(f1_scores_0)
f1_scores_1 = pd.DataFrame(f1_scores_1)
f1_scores_2 = pd.DataFrame(f1_scores_2)
summary = [accuracy, f1_score_avg,
           f1_scores_0, f1_scores_1, f1_scores_2]
summary_report = pd.concat(summary, axis=1)
summary_report.columns = ['Accuracy', 'Avg f1_score', 'F1_score_0',
                          'F1_score_1', 'F1_score_2']
summary_report.insert(0, 'Models', clf_series.keys(), allow_duplicates=True)
summary_report_copy = summary_report.copy()
summary_report_copy = summary_report_copy.sort_values(by='Avg f1_score',
                                                      ascending=False)
print(summary_report_copy.head())

# select the best model based on average f1_score
model_selection = pd.concat([pd.DataFrame(clf_series.keys()),
                             f1_score_avg], axis=1)
# I determine that the best model would be the model with highest avg f1_score
model_selection.columns = ['Models', 'Avg f1_score']
model_selection_copy = model_selection.copy()
model_selection_copy = model_selection_copy.sort_values(by='Avg f1_score',
                                                        ascending=False)
best_model_name = model_selection_copy.iloc[0, 0]
print('The best model is {}'.format(best_model_name))
print(' ')
clf = clf_series[best_model_name]

# prepared for test set
# like what's been done in validation
# by running below codes, it will also print out
# accuracy, avg f1_score, by-class f1_score
# and confusion matrix in number format
test = preprocessing('test')

if loaded is True:
    print('model used: {}'.format(best_model_name))
    x_test = test['reviewBody']
    y_test = test['Sentiment']

    x_test_count = cv.transform(x_test)
    x_test_tfidf = tt.transform(x_test_count)
    y_pred = clf.predict(x_test_tfidf)

    # print model performance for test
    print('Test performance')
    print('--------------------------------------------')
    accuracy = metrics.accuracy_score(y_test, y_pred)
    print('Accuracy: ' + str(accuracy))

    f1_score = metrics.classification_report(
                y_test, y_pred, output_dict=True)
    f1_score_avg = metrics.f1_score(y_test, y_pred, average='macro')
    print('Average f1_score: ' + str(f1_score_avg))

    f1_scores_0 = f1_score.get('0', {}).get('f1-score')
    f1_scores_1 = f1_score.get('1', {}).get('f1-score')
    f1_scores_2 = f1_score.get('2', {}).get('f1-score')
    print('Negative f1_score: ' + str(f1_scores_0))
    print('Neutral f1_score: ' + str(f1_scores_1))
    print('Positive f1_score: ' + str(f1_scores_2))

    print('Confusion matrix: ')
    confusion_matrix = pd.DataFrame(
                       metrics.confusion_matrix(y_test,
                                                y_pred,
                                                labels=clf.classes_))
    confusion_matrix.columns = ['Negative', 'Neutral', 'Positive']
    confusion_matrix.insert(0, ' ', ['Negative', 'Neutral', 'Positive'],
                            allow_duplicates=True)
    print(confusion_matrix)
